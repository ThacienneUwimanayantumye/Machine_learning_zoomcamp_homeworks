{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a290374d",
      "metadata": {},
      "source": [
        "# Machine Learning Zoomcamp - Homework 3: Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efe99029",
      "metadata": {},
      "source": [
        "## Dataset Preparation\n",
        "\n",
        "First, let's load necessary libraries, load and prepare the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "82ccac60",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.metrics import mutual_info_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "4016c946",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (1462, 9)\n",
            "\n",
            "First few rows:\n",
            "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
            "0      paid_ads         NaN                         1        79450.0   \n",
            "1  social_media      retail                         1        46992.0   \n",
            "2        events  healthcare                         5        78796.0   \n",
            "3      paid_ads      retail                         2        83843.0   \n",
            "4      referral   education                         3        85012.0   \n",
            "\n",
            "  employment_status       location  interaction_count  lead_score  converted  \n",
            "0        unemployed  south_america                  4        0.94          1  \n",
            "1          employed  south_america                  1        0.80          0  \n",
            "2        unemployed      australia                  3        0.69          1  \n",
            "3               NaN      australia                  1        0.87          0  \n",
            "4     self_employed         europe                  3        0.62          1  \n",
            "\n",
            "Column names:\n",
            "['lead_source', 'industry', 'number_of_courses_viewed', 'annual_income', 'employment_status', 'location', 'interaction_count', 'lead_score', 'converted']\n",
            "\n",
            "Missing values:\n",
            "lead_source                 128\n",
            "industry                    134\n",
            "number_of_courses_viewed      0\n",
            "annual_income               181\n",
            "employment_status           100\n",
            "location                     63\n",
            "interaction_count             0\n",
            "lead_score                    0\n",
            "converted                     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('course_lead_scoring.csv')\n",
        "\n",
        "# Print the shape and know how big is our dataset\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "\n",
        "# View the first few raws \n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Print the names of features we have in the dataset\n",
        "print(f\"\\nColumn names:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Checking for missing values\n",
        "print(f\"\\nMissing values:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70127db1",
      "metadata": {},
      "source": [
        "### Handle Missing Values\n",
        "- For categorical features: replace missing values with 'NA'\n",
        "- For numerical features: replace missing values with 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "fa02405a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categorical columns: ['lead_source', 'industry', 'employment_status', 'location']\n",
            "Numerical columns: ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
            "\n",
            "Missing values after handling:\n",
            "lead_source                 0\n",
            "industry                    0\n",
            "number_of_courses_viewed    0\n",
            "annual_income               0\n",
            "employment_status           0\n",
            "location                    0\n",
            "interaction_count           0\n",
            "lead_score                  0\n",
            "converted                   0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Identifying categorical and numerical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Removing target from lists if present\n",
        "if 'converted' in categorical_cols:\n",
        "    categorical_cols.remove('converted')\n",
        "if 'converted' in numerical_cols:\n",
        "    numerical_cols.remove('converted')\n",
        "\n",
        "#printing the columns to see if the target variable is excluded\n",
        "print(f\"Categorical columns: {categorical_cols}\")\n",
        "print(f\"Numerical columns: {numerical_cols}\")\n",
        "\n",
        "# Fill missing values\n",
        "for col in categorical_cols:\n",
        "    df[col] = df[col].fillna('NA')\n",
        "\n",
        "for col in numerical_cols:\n",
        "    df[col] = df[col].fillna(0.0)\n",
        "\n",
        "# Checking for missing values after handling\n",
        "print(\"\\nMissing values after handling:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c33e233d",
      "metadata": {},
      "source": [
        "**Main Findings:**\n",
        "- Dataset has 1,462 rows and 9 columns\n",
        "- Missing values found in: `lead_source` (128), `industry` (134), `annual_income` (181), `employment_status` (100), `location` (63)\n",
        "- Categorical columns: `lead_source`, `industry`, `employment_status`, `location`\n",
        "- Numerical columns: `number_of_courses_viewed`, `annual_income`, `interaction_count`, `lead_score`\n",
        "- Target variable: `converted` (whether client signed up)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc92057",
      "metadata": {},
      "source": [
        "---\n",
        "## Question 1\n",
        "\n",
        "**What is the most frequent observation (mode) for the column `industry`?**\n",
        "\n",
        "Options:\n",
        "- `NA`\n",
        "- `technology`\n",
        "- `healthcare`\n",
        "- `retail`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "a43715ce",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most frequent observation (mode) for 'industry': retail\n"
          ]
        }
      ],
      "source": [
        "# Find the mode of 'industry' column\n",
        "industry_mode = df['industry'].mode()[0]\n",
        "print(f\"The most frequent observation (mode) for 'industry': {industry_mode}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "464de656",
      "metadata": {},
      "source": [
        "### Answer: `retail`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f8875b3",
      "metadata": {},
      "source": [
        "**Main Findings:**\n",
        "\n",
        "After handling missing values (replaced with 'NA'), the `industry` column's mode is **retail**. This indicates that the majority of leads in this dataset come from the retail industry. This is valuable information as it suggests the platform or service being marketed has strong appeal in the retail sector, which could inform marketing strategies and resource allocation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6eb12e5",
      "metadata": {},
      "source": [
        "---\n",
        "## Question 2\n",
        "\n",
        "**Create the correlation matrix for the numerical features of your dataset. What are the two features that have the biggest correlation?**\n",
        "\n",
        "Options:\n",
        "- `interaction_count` and `lead_score`\n",
        "- `number_of_courses_viewed` and `lead_score`\n",
        "- `number_of_courses_viewed` and `interaction_count`\n",
        "- `annual_income` and `interaction_count`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "3aae4c6d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation matrix:\n",
            "                          number_of_courses_viewed  annual_income  \\\n",
            "number_of_courses_viewed                  1.000000       0.009770   \n",
            "annual_income                             0.009770       1.000000   \n",
            "interaction_count                        -0.023565       0.027036   \n",
            "lead_score                               -0.004879       0.015610   \n",
            "\n",
            "                          interaction_count  lead_score  \n",
            "number_of_courses_viewed          -0.023565   -0.004879  \n",
            "annual_income                      0.027036    0.015610  \n",
            "interaction_count                  1.000000    0.009888  \n",
            "lead_score                         0.009888    1.000000  \n",
            "\n",
            "Correlations for specified pairs:\n",
            "interaction_count & lead_score: 0.0099\n",
            "number_of_courses_viewed & lead_score: -0.0049\n",
            "number_of_courses_viewed & interaction_count: -0.0236\n",
            "annual_income & interaction_count: 0.0270\n"
          ]
        }
      ],
      "source": [
        "# Get numerical features (excluding target)\n",
        "numerical_features = [col for col in df.select_dtypes(include=['int64', 'float64']).columns \n",
        "                     if col != 'converted']\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = df[numerical_features].corr()\n",
        "print(\"Correlation matrix:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Check specific pairs\n",
        "pairs = [\n",
        "    ('interaction_count', 'lead_score'),\n",
        "    ('number_of_courses_viewed', 'lead_score'),\n",
        "    ('number_of_courses_viewed', 'interaction_count'),\n",
        "    ('annual_income', 'interaction_count')\n",
        "]\n",
        "\n",
        "print(\"\\nCorrelations for specified pairs:\")\n",
        "for feat1, feat2 in pairs:\n",
        "    corr = df[feat1].corr(df[feat2])\n",
        "    print(f\"{feat1} & {feat2}: {corr:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e755cd4f",
      "metadata": {},
      "source": [
        "**Results:**\n",
        "- `interaction_count` & `lead_score`: 0.0099\n",
        "- `number_of_courses_viewed` & `lead_score`: -0.0049\n",
        "- `number_of_courses_viewed` & `interaction_count`: -0.0236\n",
        "- `annual_income` & `interaction_count`: **0.0270** ← Highest\n",
        "\n",
        "**Main Findings:**\n",
        "\n",
        "The highest correlation among the specified pairs is between **annual_income** and **interaction_count** (0.0270). However, it's important to note that all correlations are very weak (close to 0), suggesting that these numerical features are largely independent of each other. This weak correlation means:\n",
        "1. Features provide different information and are not redundant\n",
        "2. Multicollinearity is not a concern for our logistic regression model\n",
        "3. The relationship between these variables is mostly linear-independent, which is actually good for modeling\n",
        "\n",
        "### Answer: `annual_income` and `interaction_count`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "371af736",
      "metadata": {},
      "source": [
        "---\n",
        "## Question 3\n",
        "\n",
        "**Calculate the mutual information score between `y` and other categorical variables in the dataset. Use the training set only. Which of these variables has the biggest mutual information score?**\n",
        "\n",
        "Options:\n",
        "- `industry`\n",
        "- `location`\n",
        "- `lead_source`\n",
        "- `employment_status`\n",
        "\n",
        "First, split the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "b6cca8eb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 877 (60.0%)\n",
            "Val size: 292 (20.0%)\n",
            "Test size: 293 (20.0%)\n"
          ]
        }
      ],
      "source": [
        "# Separate features and target\n",
        "y = df['converted'].values\n",
        "df_features = df.drop('converted', axis=1)\n",
        "\n",
        "# Split: 60% train, 20% val, 20% test\n",
        "df_train, df_temp, y_train, y_temp = train_test_split(\n",
        "    df_features, y, test_size=0.4, random_state=42\n",
        ")\n",
        "\n",
        "df_val, df_test, y_val, y_test = train_test_split(\n",
        "    df_temp, y_temp, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Train size: {len(df_train)} ({len(df_train)/len(df)*100:.1f}%)\")\n",
        "print(f\"Val size: {len(df_val)} ({len(df_val)/len(df)*100:.1f}%)\")\n",
        "print(f\"Test size: {len(df_test)} ({len(df_test)/len(df)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a83ca3ac",
      "metadata": {},
      "source": [
        "Calculate mutual information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "c87c964d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lead_source: 0.03\n",
            "industry: 0.02\n",
            "employment_status: 0.02\n",
            "location: 0.0\n",
            "\n",
            "Feature with highest MI score: lead_source = 0.03\n"
          ]
        }
      ],
      "source": [
        "# Get categorical features from training set\n",
        "categorical_features = df_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Calculate MI scores\n",
        "mi_scores = {}\n",
        "for col in categorical_features:\n",
        "    mi = mutual_info_score(y_train, df_train[col])\n",
        "    mi_scores[col] = round(mi, 2)\n",
        "    print(f\"{col}: {mi_scores[col]}\")\n",
        "\n",
        "max_mi_feature = max(mi_scores, key=mi_scores.get)\n",
        "print(f\"\\nFeature with highest MI score: {max_mi_feature} = {mi_scores[max_mi_feature]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18a16dba",
      "metadata": {},
      "source": [
        "**Results:**\n",
        "- `lead_source`: **0.03** ← Highest\n",
        "- `industry`: 0.02\n",
        "- `employment_status`: 0.02\n",
        "- `location`: 0.00\n",
        "\n",
        "### Answer: `lead_source`\n",
        "\n",
        "**Main Findings:**\n",
        "\n",
        "**lead_source** has the highest mutual information score (0.03) with the target variable `converted`. Mutual information measures the amount of information one variable provides about another. This finding indicates that:\n",
        "1. **lead_source** is the most informative categorical feature for predicting conversion\n",
        "2. The source of the lead (e.g., paid ads, social media, referral) has the strongest relationship with whether someone converts\n",
        "3. `location` has essentially zero mutual information (0.00), suggesting it provides almost no predictive value\n",
        "4. All MI scores are relatively low, indicating weak but existing relationships\n",
        "\n",
        "This insight is crucial for marketing: the channel through which leads are acquired matters more than their location or industry when predicting conversion."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e9d1d6",
      "metadata": {},
      "source": [
        "---\n",
        "## Question 4\n",
        "\n",
        "**Train a logistic regression model with one-hot encoding. What accuracy did you get on the validation dataset?**\n",
        "\n",
        "Options:\n",
        "- 0.64\n",
        "- 0.74\n",
        "- 0.84\n",
        "- 0.94"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "2cb5aa8d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature matrix shape: (877, 31)\n",
            "Number of features after one-hot encoding: 31\n",
            "\n",
            "Validation Accuracy: 0.7432\n",
            "Validation Accuracy (rounded to 2 decimals): 0.74\n"
          ]
        }
      ],
      "source": [
        "# Prepare data with one-hot encoding using DictVectorizer\n",
        "train_dicts = df_train.to_dict(orient='records')\n",
        "val_dicts = df_val.to_dict(orient='records')\n",
        "\n",
        "dv = DictVectorizer(sparse=False)\n",
        "X_train = dv.fit_transform(train_dicts)\n",
        "X_val = dv.transform(val_dicts)\n",
        "\n",
        "print(f\"Feature matrix shape: {X_train.shape}\")\n",
        "print(f\"Number of features after one-hot encoding: {X_train.shape[1]}\")\n",
        "\n",
        "# Train logistic regression\n",
        "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Calculate accuracy\n",
        "y_pred = model.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "accuracy_rounded = round(accuracy, 2)\n",
        "\n",
        "print(f\"\\nValidation Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Validation Accuracy (rounded to 2 decimals): {accuracy_rounded}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b71582d7",
      "metadata": {},
      "source": [
        "**Result:** Validation Accuracy = 0.74 (0.7432 before rounding)\n",
        "\n",
        "### Answer: 0.74\n",
        "\n",
        "**Main Findings:**\n",
        "\n",
        "The logistic regression model achieved a **74.32% accuracy** on the validation set. This means:\n",
        "1. The model correctly predicts conversion status for about 3 out of 4 leads\n",
        "2. After one-hot encoding, we have 31 features (from 8 original features)\n",
        "3. An accuracy of 74% is reasonably good for a baseline model, though there's room for improvement\n",
        "4. The model performs better than random guessing (50%) and suggests that the features do contain predictive information about conversion\n",
        "\n",
        "The model provides a solid foundation that could be further improved through feature engineering, trying different algorithms, or ensemble methods."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41bf638b",
      "metadata": {},
      "source": [
        "---\n",
        "## Question 5\n",
        "\n",
        "**Using feature elimination technique, which feature has the smallest difference in accuracy when removed?**\n",
        "\n",
        "Options:\n",
        "- `'industry'`\n",
        "- `'employment_status'`\n",
        "- `'lead_score'`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "65dff021",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 0.7432\n",
            "\n",
            "Without 'industry':\n",
            "  Accuracy: 0.7432\n",
            "  Difference: 0.0000\n",
            "\n",
            "Without 'employment_status':\n",
            "  Accuracy: 0.7466\n",
            "  Difference: -0.0034\n",
            "\n",
            "Without 'lead_score':\n",
            "  Accuracy: 0.7432\n",
            "  Difference: 0.0000\n",
            "\n",
            "Feature with smallest difference: 'industry' = 0.0000\n"
          ]
        }
      ],
      "source": [
        "# Store the baseline accuracy\n",
        "baseline_accuracy = accuracy  # from Question 4\n",
        "\n",
        "print(f\"Baseline accuracy: {baseline_accuracy:.4f}\")\n",
        "\n",
        "# Features to test\n",
        "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
        "\n",
        "feature_differences = {}\n",
        "\n",
        "for feature in features_to_test:\n",
        "    # Create dataset without this feature\n",
        "    df_train_temp = df_train.drop(feature, axis=1)\n",
        "    df_val_temp = df_val.drop(feature, axis=1)\n",
        "    \n",
        "    # Transform to dict and one-hot encode\n",
        "    train_dicts_temp = df_train_temp.to_dict(orient='records')\n",
        "    val_dicts_temp = df_val_temp.to_dict(orient='records')\n",
        "    \n",
        "    dv_temp = DictVectorizer(sparse=False)\n",
        "    X_train_temp = dv_temp.fit_transform(train_dicts_temp)\n",
        "    X_val_temp = dv_temp.transform(val_dicts_temp)\n",
        "    \n",
        "    # Train model\n",
        "    model_temp = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
        "    model_temp.fit(X_train_temp, y_train)\n",
        "    \n",
        "    # Calculate accuracy and difference\n",
        "    y_pred_temp = model_temp.predict(X_val_temp)\n",
        "    accuracy_temp = accuracy_score(y_val, y_pred_temp)\n",
        "    difference = baseline_accuracy - accuracy_temp\n",
        "    \n",
        "    feature_differences[feature] = difference\n",
        "    print(f\"\\nWithout '{feature}':\")\n",
        "    print(f\"  Accuracy: {accuracy_temp:.4f}\")\n",
        "    print(f\"  Difference: {difference:.4f}\")\n",
        "\n",
        "# Find feature with smallest difference\n",
        "min_diff_feature = min(feature_differences, key=lambda k: abs(feature_differences[k]))\n",
        "print(f\"\\nFeature with smallest difference: '{min_diff_feature}' = {feature_differences[min_diff_feature]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e243799e",
      "metadata": {},
      "source": [
        "**Results:**\n",
        "- Without `'industry'`: Difference = **0.0000** ← Smallest\n",
        "- Without `'employment_status'`: Difference = -0.0034\n",
        "- Without `'lead_score'`: Difference = 0.0000\n",
        "\n",
        "### Answer: `'industry'`\n",
        "\n",
        "**Main Findings:**\n",
        "\n",
        "**'industry'** has the smallest difference (0.0000), meaning removing this feature has virtually no impact on model accuracy. Key insights:\n",
        "1. **industry** is the least useful feature - it contributes nothing to model performance\n",
        "2. This aligns with Question 3 findings where industry had low mutual information (0.02)\n",
        "3. **employment_status** actually slightly improves accuracy when removed (negative difference), suggesting it might add noise\n",
        "4. **lead_score** also has zero difference, making it equally \"useless\" with industry\n",
        "5. This suggests we could simplify the model by removing these features without sacrificing performance\n",
        "\n",
        "This is valuable for model deployment: simpler models with fewer features are easier to maintain, faster to run, and less prone to overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aebc16d4",
      "metadata": {},
      "source": [
        "---\n",
        "## Question 6\n",
        "\n",
        "**Train regularized logistic regression with different C values: [0.01, 0.1, 1, 10, 100]. Which C leads to the best accuracy on the validation set?**\n",
        "\n",
        "Options:\n",
        "- 0.01\n",
        "- 0.1\n",
        "- 1\n",
        "- 10\n",
        "- 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "df4d08b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C = 0.01: Accuracy = 0.743\n",
            "C = 0.1: Accuracy = 0.743\n",
            "C = 1: Accuracy = 0.743\n",
            "C = 10: Accuracy = 0.743\n",
            "C = 100: Accuracy = 0.743\n",
            "\n",
            "Best C value: 0.01 with accuracy: 0.743\n"
          ]
        }
      ],
      "source": [
        "C_values = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# Use the original full feature set\n",
        "train_dicts = df_train.to_dict(orient='records')\n",
        "val_dicts = df_val.to_dict(orient='records')\n",
        "\n",
        "dv = DictVectorizer(sparse=False)\n",
        "X_train = dv.fit_transform(train_dicts)\n",
        "X_val = dv.transform(val_dicts)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for C in C_values:\n",
        "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred = model.predict(X_val)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    accuracy_rounded = round(accuracy, 3)\n",
        "    \n",
        "    results[C] = accuracy_rounded\n",
        "    print(f\"C = {C}: Accuracy = {accuracy_rounded}\")\n",
        "\n",
        "# Find best C\n",
        "best_accuracy = max(results.values())\n",
        "best_C_values = [C for C, acc in results.items() if acc == best_accuracy]\n",
        "best_C = min(best_C_values)  # If tie, select smallest C\n",
        "\n",
        "print(f\"\\nBest C value: {best_C} with accuracy: {best_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d1aeeb0",
      "metadata": {},
      "source": [
        "**Results:**\n",
        "- C = 0.01: 0.743 ← **Best (smallest C when tied)**\n",
        "- C = 0.1: 0.743\n",
        "- C = 1: 0.743\n",
        "- C = 10: 0.743\n",
        "- C = 100: 0.743\n",
        "\n",
        "**Main Findings:**\n",
        "\n",
        "All C values achieve the same accuracy (0.743), so we select **C = 0.01** (the smallest value as per instructions). This surprising result reveals important insights:\n",
        "\n",
        "1. **Model is not overfitting**: If overfitting were an issue, stronger regularization (smaller C) would improve performance\n",
        "2. **Regularization doesn't matter here**: The consistent accuracy across all C values suggests the model is already well-regularized or the features are not causing overfitting\n",
        "3. **Simple features**: The dataset's features are relatively simple and don't have complex interactions that would benefit from different regularization strengths\n",
        "4. **Choose smaller C for robustness**: When performance is equal, choosing smaller C (stronger regularization) is preferred as it:\n",
        "   - Prevents potential overfitting on new data\n",
        "   - Produces more generalizable coefficients\n",
        "   - Is more conservative and robust\n",
        "\n",
        "This suggests our baseline model from Question 4 is already quite stable and well-calibrated.\n",
        "\n",
        "### Answer: 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d680e983",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary of Answers\n",
        "\n",
        "| Question | Answer | Value |\n",
        "|----------|--------|-------|\n",
        "| Q1: Mode of 'industry' | retail | - |\n",
        "| Q2: Highest correlation pair | annual_income & interaction_count | 0.0270 |\n",
        "| Q3: Highest MI score | lead_source | 0.03 |\n",
        "| Q4: Validation accuracy | 0.74 | 74.32% |\n",
        "| Q5: Least useful feature | 'industry' | Difference: 0.0000 |\n",
        "| Q6: Best C value | 0.01 | Accuracy: 0.743 |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "221d7ccd",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Data Quality**: The dataset has moderate missing values that were handled appropriately\n",
        "2. **Feature Independence**: Numerical features show very weak correlations, reducing multicollinearity concerns\n",
        "3. **Lead Source Matters**: The source of the lead is the most predictive categorical feature\n",
        "4. **Baseline Performance**: A simple logistic regression achieves 74% accuracy\n",
        "5. **Feature Redundancy**: 'industry' feature can be removed without impacting performance\n",
        "6. **Regularization Stability**: The model shows consistent performance across all regularization strengths"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
